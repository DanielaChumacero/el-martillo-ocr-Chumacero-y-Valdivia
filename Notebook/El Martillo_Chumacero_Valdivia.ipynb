{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jiKGPI5UFVq",
        "outputId": "47549b45-7be0-40c8-81fe-42d8d65fe00c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Instalaci√≥n completada\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ## 1. Instalaci√≥n de dependencias\n",
        "# **MODIFICADO:** Se agreg√≥ Tesseract OCR y se removi√≥ Anthropic\n",
        "\n",
        "# %%\n",
        "# Instalaci√≥n de Tesseract OCR y bibliotecas necesarias\n",
        "!apt-get install tesseract-ocr tesseract-ocr-spa -y -qq\n",
        "!pip install pytesseract pandas matplotlib seaborn pillow opencv-python -q\n",
        "\n",
        "print(\"‚úì Instalaci√≥n completada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDd-t_nqYLAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 2. Importaci√≥n de bibliotecas\n",
        "\n",
        "# %%\n",
        "import anthropic\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import json\n",
        "import base64\n",
        "import io\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Configurar estilo de visualizaci√≥n\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")# %% [markdown]\n",
        "# ## 2. Importaci√≥n de bibliotecas\n",
        "\n",
        "# %%\n",
        "import anthropic\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import json\n",
        "import base64\n",
        "import io\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Configurar estilo de visualizaci√≥n\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")"
      ],
      "metadata": {
        "id": "feYWsn5GVaSo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "1c1e7963-d27c-44a1-bcc4-60d8584949e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'anthropic'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3672302103.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0manthropic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'anthropic'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 3. Configuraci√≥n de la API de Claude\n",
        "\n",
        "# %%\n",
        "# IMPORTANTE: Configura tu API key de Anthropic\n",
        "# Opci√≥n 1: Variable de entorno (recomendado)\n",
        "# Opci√≥n 2: Directamente aqu√≠ (NO subir a GitHub con la key)\n",
        "\n",
        "# Para Colab, puedes usar:\n",
        "from google.colab import userdata\n",
        "try:\n",
        "    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "except:\n",
        "    # Si no est√° en Colab secrets, p√≠dela al usuario\n",
        "    ANTHROPIC_API_KEY = input(\"Ingresa tu API Key de Anthropic: \")\n",
        "\n",
        "# Inicializar cliente\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "TyfsMwNcUU9K",
        "outputId": "4c69517a-172c-457c-f481-3ddba8a5d78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3878391208.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Si no est√° en Colab secrets, p√≠dela al usuario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mANTHROPIC_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ingresa tu API Key de Anthropic: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Inicializar cliente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 5. Carga y visualizaci√≥n de la imagen\n",
        "\n",
        "# %%\n",
        "# Ruta de la imagen del peri√≥dico\n",
        "IMAGE_PATH = \"data/el_martillo/page_01.png\"\n",
        "\n",
        "# Crear directorio si no existe\n",
        "os.makedirs(os.path.dirname(IMAGE_PATH), exist_ok=True)\n",
        "\n",
        "# NOTA: Debes descargar una p√°gina del peri√≥dico El Martillo de:\n",
        "# https://fuenteshistoricasdelperu.com/2020/12/06/el-martillo-chiclayo-1903-1919/\n",
        "# y guardarla en: data/el_martillo/page_01.png\n",
        "\n",
        "# Verificar que existe la imagen\n",
        "if os.path.exists(IMAGE_PATH):\n",
        "    print(f\"‚úì Imagen encontrada en: {IMAGE_PATH}\")\n",
        "    img = display_image(IMAGE_PATH)\n",
        "    print(f\"Dimensiones: {img.size[0]}x{img.size[1]} pixels\")\n",
        "else:\n",
        "    print(f\"‚ö† ADVERTENCIA: No se encontr√≥ la imagen en {IMAGE_PATH}\")\n",
        "    print(\"Por favor, descarga una p√°gina del peri√≥dico y gu√°rdala en esa ubicaci√≥n.\")\n"
      ],
      "metadata": {
        "id": "bsk8ZizTUXik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 6. Extracci√≥n de texto con Claude OCR\n",
        "\n",
        "# %%\n",
        "def extract_text_with_claude(image_path):\n",
        "    \"\"\"\n",
        "    Usa Claude Vision API para extraer texto de la imagen del peri√≥dico\n",
        "    \"\"\"\n",
        "    # Codificar imagen\n",
        "    image_data = encode_image_to_base64(image_path)\n",
        "    media_type = get_image_media_type(image_path)\n",
        "\n",
        "    # Prompt para OCR estructurado\n",
        "    prompt = \"\"\"Analiza esta p√°gina del peri√≥dico hist√≥rico \"El Martillo\" de Chiclayo, Per√∫ (1903-1919).\n",
        "\n",
        "Extrae TODA la informaci√≥n visible y estruct√∫rala de la siguiente manera:\n",
        "\n",
        "1. METADATOS DE LA P√ÅGINA:\n",
        "   - Fecha de publicaci√≥n (si es visible)\n",
        "   - N√∫mero de edici√≥n/ejemplar (si es visible)\n",
        "   - A√±o\n",
        "\n",
        "2. CONTENIDO ESTRUCTURADO:\n",
        "   Para cada art√≠culo, secci√≥n o elemento de la p√°gina, proporciona:\n",
        "   - T√≠tulo/Encabezado principal\n",
        "   - Secci√≥n (si est√° identificada: noticias, editorial, anuncios, avisos, etc.)\n",
        "   - Tipo de contenido (art√≠culo, anuncio, aviso legal, editorial, nota social, etc.)\n",
        "   - Texto completo transcrito (preserva la ortograf√≠a original, incluso si tiene errores)\n",
        "\n",
        "3. ANUNCIOS Y AVISOS:\n",
        "   Lista todos los anuncios comerciales o avisos que aparezcan\n",
        "\n",
        "Por favor, s√© exhaustivo y transcribe todo el texto legible, incluyendo:\n",
        "- Art√≠culos completos\n",
        "- Anuncios publicitarios\n",
        "- Avisos legales\n",
        "- Notas sociales\n",
        "- Cualquier otro texto visible\n",
        "\n",
        "Presenta la informaci√≥n en formato JSON con esta estructura:\n",
        "{\n",
        "  \"metadata\": {\n",
        "    \"date\": \"fecha si est√° visible\",\n",
        "    \"issue_number\": \"n√∫mero si est√° visible\",\n",
        "    \"year\": \"a√±o\"\n",
        "  },\n",
        "  \"content\": [\n",
        "    {\n",
        "      \"headline\": \"t√≠tulo del art√≠culo/secci√≥n\",\n",
        "      \"section\": \"nombre de la secci√≥n\",\n",
        "      \"type\": \"art√≠culo/anuncio/aviso/editorial/etc\",\n",
        "      \"text_excerpt\": \"texto completo transcrito\"\n",
        "    }\n",
        "  ]\n",
        "}\"\"\"\n",
        "\n",
        "    # Llamada a la API\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-sonnet-4-20250514\",\n",
        "        max_tokens=4096,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image\",\n",
        "                        \"source\": {\n",
        "                            \"type\": \"base64\",\n",
        "                            \"media_type\": media_type,\n",
        "                            \"data\": image_data,\n",
        "                        },\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": prompt\n",
        "                    }\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Extraer respuesta\n",
        "    response_text = message.content[0].text\n",
        "    return response_text\n",
        "\n",
        "# Ejecutar OCR\n",
        "print(\"Procesando imagen con Claude OCR...\")\n",
        "print(\"Esto puede tomar 30-60 segundos...\\n\")\n",
        "\n",
        "if os.path.exists(IMAGE_PATH):\n",
        "    raw_ocr_result = extract_text_with_claude(IMAGE_PATH)\n",
        "    print(\"‚úì OCR completado\\n\")\n",
        "    print(\"Resultado extra√≠do:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(raw_ocr_result)\n",
        "    print(\"=\" * 80)\n",
        "else:\n",
        "    print(\"‚ö† No se puede ejecutar OCR sin la imagen\")\n",
        "    raw_ocr_result = None"
      ],
      "metadata": {
        "id": "SJTFLUQrUejD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 7. Procesamiento y limpieza de datos\n",
        "\n",
        "# %%\n",
        "def parse_ocr_json(ocr_text):\n",
        "    \"\"\"\n",
        "    Parsea el resultado del OCR y lo convierte a estructura de datos\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Intentar extraer JSON del texto\n",
        "        # A veces Claude incluye el JSON entre ```json y ```\n",
        "        if \"```json\" in ocr_text:\n",
        "            start = ocr_text.find(\"```json\") + 7\n",
        "            end = ocr_text.find(\"```\", start)\n",
        "            json_text = ocr_text[start:end].strip()\n",
        "        elif \"```\" in ocr_text:\n",
        "            start = ocr_text.find(\"```\") + 3\n",
        "            end = ocr_text.find(\"```\", start)\n",
        "            json_text = ocr_text[start:end].strip()\n",
        "        else:\n",
        "            json_text = ocr_text\n",
        "\n",
        "        # Parsear JSON\n",
        "        data = json.loads(json_text)\n",
        "        return data\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error al parsear JSON: {e}\")\n",
        "        print(\"Intentando extraer datos manualmente...\")\n",
        "        return None\n",
        "\n",
        "def create_dataframe_from_ocr(ocr_data):\n",
        "    \"\"\"\n",
        "    Convierte los datos del OCR en un DataFrame de pandas\n",
        "    \"\"\"\n",
        "    if ocr_data is None:\n",
        "        return None\n",
        "\n",
        "    # Extraer metadatos\n",
        "    metadata = ocr_data.get('metadata', {})\n",
        "    date = metadata.get('date', 'N/A')\n",
        "    issue_number = metadata.get('issue_number', 'N/A')\n",
        "    year = metadata.get('year', 'N/A')\n",
        "\n",
        "    # Crear lista de registros\n",
        "    records = []\n",
        "    for item in ocr_data.get('content', []):\n",
        "        record = {\n",
        "            'date': date,\n",
        "            'issue_number': issue_number,\n",
        "            'headline': item.get('headline', ''),\n",
        "            'section': item.get('section', 'N/A'),\n",
        "            'type': item.get('type', 'N/A'),\n",
        "            'text_excerpt': item.get('text_excerpt', '')\n",
        "        }\n",
        "        records.append(record)\n",
        "\n",
        "    # Crear DataFrame\n",
        "    df = pd.DataFrame(records)\n",
        "    return df\n",
        "\n",
        "# Procesar datos\n",
        "if raw_ocr_result:\n",
        "    print(\"Procesando datos extra√≠dos...\")\n",
        "    parsed_data = parse_ocr_json(raw_ocr_result)\n",
        "\n",
        "    if parsed_data:\n",
        "        df = create_dataframe_from_ocr(parsed_data)\n",
        "        print(f\"\\n‚úì DataFrame creado con {len(df)} registros\\n\")\n",
        "        print(\"Vista previa de los datos:\")\n",
        "        print(df.head())\n",
        "        print(f\"\\nColumnas: {list(df.columns)}\")\n",
        "    else:\n",
        "        print(\"‚ö† No se pudo crear el DataFrame autom√°ticamente\")\n",
        "        df = None\n",
        "else:\n",
        "    df = None"
      ],
      "metadata": {
        "id": "PVSjxaxqUkfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 8. Limpieza y normalizaci√≥n de datos\n",
        "\n",
        "# %%\n",
        "def clean_and_normalize_data(df):\n",
        "    \"\"\"\n",
        "    Limpia y normaliza los datos extra√≠dos\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    # Limpiar espacios en blanco\n",
        "    for col in df_clean.columns:\n",
        "        if df_clean[col].dtype == 'object':\n",
        "            df_clean[col] = df_clean[col].str.strip()\n",
        "\n",
        "    # Normalizar tipos de contenido\n",
        "    type_mapping = {\n",
        "        'articulo': 'art√≠culo',\n",
        "        'noticia': 'art√≠culo',\n",
        "        'nota': 'art√≠culo',\n",
        "        'aviso': 'anuncio',\n",
        "        'publicidad': 'anuncio',\n",
        "        'editorial': 'editorial',\n",
        "        'otro': 'otro'\n",
        "    }\n",
        "\n",
        "    df_clean['type'] = df_clean['type'].str.lower()\n",
        "    df_clean['type'] = df_clean['type'].replace(type_mapping)\n",
        "\n",
        "    # Limitar longitud de extractos para visualizaci√≥n\n",
        "    df_clean['text_length'] = df_clean['text_excerpt'].str.len()\n",
        "\n",
        "    # Agregar fecha de procesamiento\n",
        "    df_clean['processing_date'] = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "if df is not None:\n",
        "    df_clean = clean_and_normalize_data(df)\n",
        "    print(\"‚úì Datos limpiados y normalizados\\n\")\n",
        "    print(\"Estad√≠sticas b√°sicas:\")\n",
        "    print(df_clean.describe(include='all'))\n",
        "else:\n",
        "    df_clean = None"
      ],
      "metadata": {
        "id": "ilNThWljUzaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 9. Guardado de datos estructurados\n",
        "\n",
        "# %%\n",
        "# Guardar CSV\n",
        "if df_clean is not None:\n",
        "    CSV_PATH = \"data/el_martillo/el_martillo_structured_data.csv\"\n",
        "    df_clean.to_csv(CSV_PATH, index=False, encoding='utf-8-sig')\n",
        "    print(f\"‚úì Datos guardados en: {CSV_PATH}\")\n",
        "\n",
        "    # Tambi√©n guardar JSON\n",
        "    JSON_PATH = \"data/el_martillo/el_martillo_structured_data.json\"\n",
        "    df_clean.to_json(JSON_PATH, orient='records', force_ascii=False, indent=2)\n",
        "    print(f\"‚úì Datos guardados en: {JSON_PATH}\")\n",
        "else:\n",
        "    print(\"‚ö† No hay datos para guardar\")\n"
      ],
      "metadata": {
        "id": "l_NSPQ45U2vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 10. An√°lisis exploratorio de datos\n",
        "\n",
        "# %%\n",
        "if df_clean is not None and not df_clean.empty:\n",
        "    print(\"AN√ÅLISIS EXPLORATORIO DE DATOS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Conteo por tipo de contenido\n",
        "    print(\"\\n1. Distribuci√≥n por tipo de contenido:\")\n",
        "    type_counts = df_clean['type'].value_counts()\n",
        "    print(type_counts)\n",
        "\n",
        "    # Conteo por secci√≥n\n",
        "    print(\"\\n2. Distribuci√≥n por secci√≥n:\")\n",
        "    section_counts = df_clean['section'].value_counts()\n",
        "    print(section_counts)\n",
        "\n",
        "    # Estad√≠sticas de longitud de texto\n",
        "    print(\"\\n3. Estad√≠sticas de longitud de texto:\")\n",
        "    print(df_clean['text_length'].describe())\n",
        "\n",
        "    # Art√≠culos m√°s largos\n",
        "    print(\"\\n4. Top 5 art√≠culos m√°s extensos:\")\n",
        "    top_articles = df_clean.nlargest(5, 'text_length')[['headline', 'type', 'text_length']]\n",
        "    print(top_articles)"
      ],
      "metadata": {
        "id": "zCZ2jeYRU5Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 11. Visualizaciones\n",
        "\n",
        "# %%\n",
        "def create_visualizations(df):\n",
        "    \"\"\"\n",
        "    Crea visualizaciones del contenido extra√≠do\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        print(\"No hay datos para visualizar\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('An√°lisis del Peri√≥dico El Martillo', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Distribuci√≥n por tipo de contenido (gr√°fico de barras)\n",
        "    ax1 = axes[0, 0]\n",
        "    type_counts = df['type'].value_counts()\n",
        "    type_counts.plot(kind='bar', ax=ax1, color='steelblue', edgecolor='black')\n",
        "    ax1.set_title('Distribuci√≥n por Tipo de Contenido', fontweight='bold')\n",
        "    ax1.set_xlabel('Tipo de Contenido')\n",
        "    ax1.set_ylabel('Cantidad')\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Agregar valores en las barras\n",
        "    for i, v in enumerate(type_counts):\n",
        "        ax1.text(i, v + 0.1, str(v), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    # 2. Distribuci√≥n por tipo (gr√°fico circular)\n",
        "    ax2 = axes[0, 1]\n",
        "    type_counts.plot(kind='pie', ax=ax2, autopct='%1.1f%%', startangle=90)\n",
        "    ax2.set_title('Proporci√≥n de Tipos de Contenido', fontweight='bold')\n",
        "    ax2.set_ylabel('')\n",
        "\n",
        "    # 3. Distribuci√≥n por secci√≥n\n",
        "    ax3 = axes[1, 0]\n",
        "    section_counts = df['section'].value_counts().head(10)\n",
        "    section_counts.plot(kind='barh', ax=ax3, color='coral', edgecolor='black')\n",
        "    ax3.set_title('Top 10 Secciones M√°s Frecuentes', fontweight='bold')\n",
        "    ax3.set_xlabel('Cantidad')\n",
        "    ax3.set_ylabel('Secci√≥n')\n",
        "    ax3.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    # 4. Distribuci√≥n de longitud de texto\n",
        "    ax4 = axes[1, 1]\n",
        "    df['text_length'].hist(bins=20, ax=ax4, color='lightgreen', edgecolor='black')\n",
        "    ax4.set_title('Distribuci√≥n de Longitud de Textos', fontweight='bold')\n",
        "    ax4.set_xlabel('Longitud (caracteres)')\n",
        "    ax4.set_ylabel('Frecuencia')\n",
        "    ax4.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Agregar l√≠nea de media\n",
        "    mean_length = df['text_length'].mean()\n",
        "    ax4.axvline(mean_length, color='red', linestyle='--', linewidth=2, label=f'Media: {mean_length:.0f}')\n",
        "    ax4.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Guardar figura\n",
        "    plt.savefig('data/el_martillo/analisis_visual.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"‚úì Visualizaci√≥n guardada en: data/el_martillo/analisis_visual.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Crear visualizaciones\n",
        "if df_clean is not None:\n",
        "    create_visualizations(df_clean)"
      ],
      "metadata": {
        "id": "g1hYDuXPU8Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 12. An√°lisis de palabras frecuentes\n",
        "\n",
        "# %%\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def analyze_frequent_words(df, top_n=20):\n",
        "    \"\"\"\n",
        "    Analiza las palabras m√°s frecuentes en los textos\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return\n",
        "\n",
        "    # Combinar todos los textos\n",
        "    all_text = ' '.join(df['text_excerpt'].fillna('').astype(str))\n",
        "\n",
        "    # Limpiar y tokenizar\n",
        "    words = re.findall(r'\\b[a-z√°√©√≠√≥√∫√±√ºA-Z√Å√â√ç√ì√ö√ë√ú]{3,}\\b', all_text.lower())\n",
        "\n",
        "    # Palabras comunes a excluir (stopwords b√°sicas en espa√±ol)\n",
        "    stopwords = {'que', 'de', 'la', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las',\n",
        "                 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como',\n",
        "                 'm√°s', 'pero', 'sus', 'le', 'ya', 'o', 'fue', 'este', 'ha', 'si',\n",
        "                 'porque', 'esta', 'son', 'entre', 'est√°', 'cuando', 'muy', 'sin',\n",
        "                 'sobre', 'ser', 'tiene', 'tambi√©n', 'me', 'hasta', 'hay', 'donde',\n",
        "                 'han', 'quien', 'est√°n', 'estado', 'desde', 'todo', 'nos', 'durante',\n",
        "                 'estados', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'fueron',\n",
        "                 'ese', 'eso', 'hab√≠a', 'ante', 'ellos', 'e', 'esto', 'm√≠', 'antes',\n",
        "                 'algunos', 'qu√©', 'unos', 'yo', 'otro', 'otras', 'otra', '√©l', 'tanto'}\n",
        "\n",
        "    # Filtrar stopwords\n",
        "    words = [w for w in words if w not in stopwords]\n",
        "\n",
        "    # Contar frecuencias\n",
        "    word_freq = Counter(words)\n",
        "    most_common = word_freq.most_common(top_n)\n",
        "\n",
        "    # Visualizar\n",
        "    if most_common:\n",
        "        words_list, counts_list = zip(*most_common)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.barh(range(len(words_list)), counts_list, color='teal', edgecolor='black')\n",
        "        plt.yticks(range(len(words_list)), words_list)\n",
        "        plt.xlabel('Frecuencia', fontweight='bold')\n",
        "        plt.ylabel('Palabra', fontweight='bold')\n",
        "        plt.title(f'Top {top_n} Palabras M√°s Frecuentes en El Martillo', fontweight='bold', fontsize=14)\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.grid(axis='x', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('data/el_martillo/palabras_frecuentes.png', dpi=300, bbox_inches='tight')\n",
        "        print(f\"‚úì An√°lisis de palabras guardado en: data/el_martillo/palabras_frecuentes.png\")\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\nPalabras m√°s frecuentes:\")\n",
        "        for word, count in most_common[:15]:\n",
        "            print(f\"  {word}: {count} veces\")\n",
        "\n",
        "if df_clean is not None:\n",
        "    analyze_frequent_words(df_clean, top_n=25)"
      ],
      "metadata": {
        "id": "6gbvWy6sVAYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 13. Resumen y conclusiones\n",
        "\n",
        "# %%\n",
        "def generate_summary(df):\n",
        "    \"\"\"\n",
        "    Genera un resumen estad√≠stico del an√°lisis\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        print(\"No hay datos para resumir\")\n",
        "        return\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"RESUMEN DEL AN√ÅLISIS\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nüìä Total de elementos extra√≠dos: {len(df)}\")\n",
        "    print(f\"üìÖ Fecha de la p√°gina: {df['date'].iloc[0] if len(df) > 0 else 'N/A'}\")\n",
        "    print(f\"üì∞ N√∫mero de edici√≥n: {df['issue_number'].iloc[0] if len(df) > 0 else 'N/A'}\")\n",
        "\n",
        "    print(\"\\nüìà Distribuci√≥n de contenido:\")\n",
        "    for tipo, cantidad in df['type'].value_counts().items():\n",
        "        porcentaje = (cantidad / len(df)) * 100\n",
        "        print(f\"  ‚Ä¢ {tipo.capitalize()}: {cantidad} ({porcentaje:.1f}%)\")\n",
        "\n",
        "    print(\"\\nüìù Estad√≠sticas de texto:\")\n",
        "    print(f\"  ‚Ä¢ Longitud promedio: {df['text_length'].mean():.0f} caracteres\")\n",
        "    print(f\"  ‚Ä¢ Longitud m√≠nima: {df['text_length'].min():.0f} caracteres\")\n",
        "    print(f\"  ‚Ä¢ Longitud m√°xima: {df['text_length'].max():.0f} caracteres\")\n",
        "\n",
        "    print(\"\\nüè∑Ô∏è Secciones identificadas:\")\n",
        "    for seccion, cantidad in df['section'].value_counts().head(5).items():\n",
        "        print(f\"  ‚Ä¢ {seccion}: {cantidad} elementos\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "if df_clean is not None:\n",
        "    generate_summary(df_clean)"
      ],
      "metadata": {
        "id": "YMV9LopsVMLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 14. Exportaci√≥n final\n",
        "\n",
        "# %%\n",
        "print(\"\\nüì¶ ARCHIVOS GENERADOS:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "files_generated = [\n",
        "    (\"Datos estructurados (CSV)\", \"data/el_martillo/el_martillo_structured_data.csv\"),\n",
        "    (\"Datos estructurados (JSON)\", \"data/el_martillo/el_martillo_structured_data.json\"),\n",
        "    (\"Visualizaci√≥n principal\", \"data/el_martillo/analisis_visual.png\"),\n",
        "    (\"An√°lisis de palabras\", \"data/el_martillo/palabras_frecuentes.png\"),\n",
        "    (\"Imagen original\", IMAGE_PATH)\n",
        "]\n",
        "\n",
        "for name, path in files_generated:\n",
        "    if os.path.exists(path):\n",
        "        size = os.path.getsize(path)\n",
        "        print(f\"‚úì {name:30s} | {path:50s} | {size:,} bytes\")\n",
        "    else:\n",
        "        print(f\"‚ö† {name:30s} | {path:50s} | NO ENCONTRADO\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n‚úÖ An√°lisis completado exitosamente!\")\n",
        "print(\"\\nPr√≥ximos pasos:\")\n",
        "print(\"1. Revisa el archivo CSV generado\")\n",
        "print(\"2. Examina las visualizaciones\")\n",
        "print(\"3. Completa el informe en formato Markdown\")\n",
        "print(\"4. Sube todos los archivos a tu repositorio de GitHub\")\n",
        "\n",
        "# %%"
      ],
      "metadata": {
        "id": "evjDUhSpVOaD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}